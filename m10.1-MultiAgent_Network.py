from typing import Literal
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.runnables.graph import CurveStyle
from langgraph.types import Command
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.checkpoint.memory import InMemorySaver
from pydantic import BaseModel, Field
from dotenv import load_dotenv
load_dotenv(override=True)


class AgentResponse(BaseModel):
    next_agent: Literal["tech_expert", "business_strategist", "ethicist", "__end__"] = Field(
        description="The next agent to call. Use '__end__' to finish the discussion."
    )
    content: str = Field(description="The message content generated by this agent.")

model = ChatGoogleGenerativeAI(model="gemini-2.0-flash-lite").with_structured_output(AgentResponse)

def tech_expert(state: MessagesState) -> Command[Literal["business_strategist", "ethicist", f"{END}"]]:
    """Tech Expert: adds feasibility & technical insights."""
    last_message = state["messages"][-1]
    response = model.invoke(
        f"You are a Tech Expert in a brainstorming network.\n"
        f"Last discussion point: {last_message}\n\n"
        f"1. Add a technical insight.\n"
        f"2. Don't overwrite the previous information, but modify and add more information relevant to your expertise.\n"
        f"3. Choose the next agent: business_strategist, ethicist, or END if finished.\n"
    )
    return Command(
        goto=response.next_agent,
        update={"messages": [AIMessage(content = response.content)]},
    )

def business_strategist(state: MessagesState) -> Command[Literal["tech_expert", "ethicist", f"{END}"]]:
    """Business Strategist: adds market/strategy perspective."""
    last_message = state["messages"][-1]
    response = model.invoke(
        f"You are a Business Strategist in a brainstorming network.\n"
        f"Last discussion point: {last_message}\n\n"
        f"1. Add a business/market insight.\n"
        f"2. Don't overwrite the previous information, but modify and add more information relevant to your expertise.\n"
        f"3. Choose the next agent: tech_expert, ethicist, or END if finished.\n"
    )
    return Command(
        goto=response.next_agent,
        update={"messages": [AIMessage(content = response.content)]},
    )

def ethicist(state: MessagesState) -> Command[Literal["tech_expert", "business_strategist", f"{END}"]]:
    """Ethicist: adds ethical & societal concerns."""
    last_message = state["messages"][-1]
    response = model.invoke(
        f"You are an Ethicist in a brainstorming network.\n"
        f"Last discussion point: {last_message}\n\n"
        f"1. Add an ethical/societal perspective.\n"
        f"2. Don't overwrite the previous information, but modify and add more information relevant to your expertise.\n"
        f"3. Choose the next agent: tech_expert, business_strategist, or END if finished.\n"
    )
    return Command(
        goto=response.next_agent,
        update={"messages": [AIMessage(content = response.content)]},
    )

graph = (
    StateGraph(MessagesState)
    .add_node(tech_expert)
    .add_node(business_strategist)
    .add_node(ethicist)
    .add_edge(START, "tech_expert")
    .compile(checkpointer=InMemorySaver())
)

CONFIG = {"configurable":{"thread_id": 1}}
for message in graph.stream({"messages":[HumanMessage(content="Quantum Machine Learning")]}, config=CONFIG, stream_mode="updates"):
    for node, updates in message.items():
            print(f"Update from node: {node}")
            if "messages" in updates:
                updates["messages"][-1].pretty_print()
            else:
                print(updates)
            print("\n")